# -*- coding: utf-8 -*-
"""Another copy of prompt_test1.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1iH2Swn-M0fw3GtLCZEe3upAPpaqpdGq8
"""

!pip install firebase-admin

pip install openai

!pip install -U sentence-transformers

from google.colab import files
from openai import OpenAI
import datetime
import random
from sentence_transformers import SentenceTransformer, util
import torch
from sklearn.cluster import KMeans
import numpy as np

import math
import datetime
from typing import List, Tuple

uploaded = files.upload()

import firebase_admin
from firebase_admin import credentials
from firebase_admin import firestore

# Path to your service account key file
# Make sure the filename matches what you uploaded
SERVICE_ACCOUNT_KEY_PATH = 'training-bd0a3-firebase-adminsdk-fbsvc-a47acf6ecd.json' # REPLACE with your actual file name

# Initialize the Firebase app
try:
    cred = credentials.Certificate(SERVICE_ACCOUNT_KEY_PATH)
    firebase_admin.initialize_app(cred)
    print("Firebase app initialized successfully!")
except Exception as e:
    print(f"Error initializing Firebase app: {e}")

# Get a Firestore client
db = firestore.client()

# --- Example: Writing data to Firestore ---
doc_ref = db.collection('colab_data').document('my_first_document')
doc_ref.set({
    'name': 'Firebase Fun',
    'version': 1.0,
    'from_colab': True,
    'timestamp': firestore.SERVER_TIMESTAMP
})
print("Data written to Firestore!")

# --- Example: Reading data from Firestore ---
doc = db.collection('colab_data').document('my_first_document').get()
if doc.exists:
    print(f"Document data: {doc.to_dict()}")
else:
    print("No such document!")

# --- Example: Querying a collection ---
docs = db.collection('colab_data').stream()
print("\nAll documents in 'colab_data' collection:")
for doc in docs:
    print(f"{doc.id} => {doc.to_dict()}")

# Reference a specific document within a collection (e.g., 'London' in 'cities')
doc_ref = db.collection('cities').document('London')

# Set data for the 'London' document
doc_ref.set({
    'name': 'London',
    'country': 'UK',
    'population': 8982000,
    'capital': True
})

print("Set document 'London' in 'cities' collection.")

# You can also use set() to update an existing document,
# or create it if it doesn't exist.
# Let's say we want to add more detail to 'Los Angeles'
la_doc_ref = db.collection('cities').document('Los Angeles')
la_doc_ref.set({
    'continent': 'North America',
    'area_sq_mi': 503
}, merge=True) # The 'merge=True' option is important here!

print("Updated 'Los Angeles' with merge: added continent and area.")

initial_variants = [
    "Summarize revenue trends using YoY and QoQ growth metrics.",
    "Write a concise paragraph highlighting revenue drivers",
    "List key revenue risks and growth factors in bullet points",
    "Summarize working capital swings and red flags clearly",
    "Give a financial due dilligence-style overview of revenue performance"

]


def upload_variants():
  for i, variant in enumerate(initial_variants):
    doc_id = f"variant_{i+1}"

    db.colletion("prompt_variants").document(doc_id).set({
        "text": variant,
        "source": "initial",
        "created_at": datetime.utcnow().isoformat(),
    })

    db.collection("ucb_stats").document(doc_id).set({
        "coyun"



    })

class FirebaseUCB:
    def __init__(self, db):
        self.db = db
        self.variant_ids, self.variants = self.load_variants()
        self.counts, self.values, self.total_count = self.load_ucb_stats()

    def load_variants(self) -> Tuple[List[str], List[str]]:
        prompt_docs = self.db.collection("prompt_variations").stream()
        variant_ids = []
        variants = []
        for doc in prompt_docs:
            variant_ids.append(doc.id)
            variants.append(doc.to_dict().get("text", ""))
        return variant_ids, variants

    def load_ucb_stats(self):
        counts = []
        values = []
        total_count = 0
        for doc_id in self.variant_ids:
            stat_ref = self.db.collection("ucb_stats").document(doc_id)
            doc = stat_ref.get()
            if doc.exists:
                stat = doc.to_dict()
                count = stat.get("count", 0)
                value = stat.get("avg_reward", 0.0)
            else:
                count = 0
                value = 0.0
            counts.append(count)
            values.append(value)
            total_count += count
        return counts, values, total_count

    def select_variant(self) -> Tuple[int, str, str]:
        # Prioritize variants with count 0
        for i, count in enumerate(self.counts):
            if count == 0:
                return i, self.variants[i], self.variant_ids[i]

        # Check if there are any variants left after filtering
        if not self.variants:
            print("Error: No prompt variants available for UCB calculation.")
            return None, None, None  # Indicate no variant was selected

        ucb_values = [
            self.values[i] + math.sqrt((2 * math.log(self.total_count)) / self.counts[i])
            for i in range(len(self.counts))
        ]
        selected_index = ucb_values.index(max(ucb_values))
        return selected_index, self.variants[selected_index], self.variant_ids[selected_index]

    def update(self, variant_index: int, reward: float):
        variant_id = self.variant_ids[variant_index]
        count = self.counts[variant_index]
        value = self.values[variant_index]

        new_count = count + 1
        new_value = ((count * value) + reward) / new_count

        self.counts[variant_index] = new_count
        self.values[variant_index] = new_value
        self.total_count += 1

        self.db.collection("ucb_stats").document(variant_id).set({
            "count": new_count,
            "avg_reward": new_value,
            "updated_at": datetime.datetime.utcnow().isoformat()
        }, merge=True)

def embeddings_filter(prompt_variations_txt, prompt_variations_id, threshold):

  prompt_variations_id_filtered = []

  model = SentenceTransformer('all-MiniLM-L6-v2')
  embeddings = model.encode(prompt_variations_txt, convert_to_tensor=True)
  cosine_sim_matrix = util.pytorch_cos_sim(embeddings, embeddings)

  keep = []
  seen = set()

  for i in range(len(prompt_variations_txt)):
      if i in seen:
          continue

      keep.append(prompt_variations_txt[i])

      # Compare i with all other prompts
      for j in range(i + 1, len(prompt_variations_txt)):
          if cosine_sim_matrix[i][j] > threshold:
              seen.add(j)


  for i in range(len(prompt_variations_txt)):
    if prompt_variations_txt[i] in keep:
      prompt_variations_id_filtered.append(prompt_variations_id[i])


  return keep, prompt_variations_id_filtered

def clustering_filter(prompt_variations_txt, prompt_variations_id, n_clusters=5):
    model = SentenceTransformer('all-MiniLM-L6-v2')
    embeddings = model.encode(prompt_variations_txt)

    kmeans = KMeans(n_clusters=n_clusters, random_state=42)
    labels = kmeans.fit_predict(embeddings)

    selected_prompts = []
    selected_ids = []

    for label in set(labels):
        idx = list(labels).index(label)  # take the first prompt from each cluster
        selected_prompts.append(prompt_variations_txt[idx])
        selected_ids.append(prompt_variations_id[idx])

    return selected_prompts, selected_ids

client = OpenAI(api_key = "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")

response = client.responses.create(
    model="gpt-4.1",
    input="Write a one-sentence bedtime story about a unicorn."
)

print(response.output_text)

general_modifiers = [
    "Write in a concise, professional tone suitable for a client-facing FDD.",
    "Organize the output using headings and bullet points.",
    "Include relevant KPIs and use numerical examples where possible.",
    "Highlight key drivers, trends, and anomalies in the analysis.",
    "Focus on what the data implies, not just what it says.",
    "Compare performance across time periods (e.g., QoQ or YoY) if applicable.",
    "Emphasize points that would be material to a potential investor or acquirer.",
    "Identify any financial red flags or unusual swings.",
    "Base all conclusions on observable facts or metrics.",
    "Match the tone and formatting of a financial due diligence report."
]

categories = {
        "Financial Analysis": ["ebitda", "margin", "profit", "cash flow", "income statement", "financial analysis", "balance sheet"],
        "Valuation & Modeling": ["dcf", "valuation", "wacc", "multiple", "terminal value", "comparable"],
        "Operational Analysis / KPIs": ["cost structure", "headcount", "supply chain", "efficiency", "kpi", "throughput"],
        "Commercial Due Diligence": ["market size", "tam", "competition", "pricing", "swot", "customer", "segment"],
        "Executive Summary / Report Drafting": ["executive summary", "conclusion", "key findings", "recommendation", "summary"],
        "Client Emails / Communications": ["email", "client", "response", "follow-up", "update", "message"],
        "Slides / Bullet Creation": ["slide", "bullet", "deck", "powerpoint", "visual", "format"],
        "Restructuring / Turnaround": ["restructuring", "liquidity", "cash runway", "turnaround", "burn rate", "cost cutting"],
        "HR / Culture / Interview": ["employee", "culture", "interview", "retention", "recruit", "staff", "hr"],
        "General Consulting / Strategy": ["benchmark", "go-to-market", "strategy", "market entry", "competitive"]
    }


category_prototypes = {
    "Financial Analysis": "Analyze EBITDA margin and cash flow trends over the last fiscal year.",
    "Valuation & Modeling": "Perform a DCF valuation and calculate enterprise value using comparables.",
    "Operational Analysis / KPIs": "Evaluate cost drivers and assess KPI performance in operations.",
    "Commercial Due Diligence": "Summarize market sizing and pricing trends in competitive landscape.",
    "Executive Summary / Report Drafting": "Write a concise executive summary of the key findings.",
    "Client Emails / Communications": "Write a client-facing email summarizing project status.",
    "Slides / Bullet Creation": "Generate slide bullets on headcount reduction strategies.",
    "Restructuring / Turnaround": "Summarize a short-term liquidity improvement plan.",
    "HR / Culture / Interview": "Explain how to improve employee retention in a consulting firm.",
    "General Consulting / Strategy": "Draft a go-to-market recommendation for a new market entry."
}

def embeddings_categorization(prompt):
  model = SentenceTransformer("all-MiniLM-L6-v2")

  category_embeddings = {
    cat: model.encode(text, convert_to_tensor=True)
    for cat, text in category_prototypes.items()
    }

  prompt_emb = model.encode(prompt, convert_to_tensor = True)
  scores = {
    cat: util.cos_sim(prompt_emb, emb)[0].item()
    for cat, emb in category_embeddings.items()
  }

  return max(scores, key=scores.get)

def categorize_prompt(prompt):
    # Removed the redefinition of categories here to use the global categories dictionary
    categories_matched = []

    # Initialize categories_counter with zeros for each category in the global dictionary
    categories_counter = [0] * len(categories)


    prompt_lower = prompt.lower()
    # Iterate through the global categories dictionary
    for i, (category, keywords) in enumerate(categories.items()):
        for keyword in keywords:
            if keyword in prompt_lower:
              categories_counter[i] += 1

    for i in range(len(categories)):
      if categories_counter[i] > 0: # Check if any keyword matched for the category
        categories_matched.append(list(categories.keys())[i]) # Get the category name by index

    if len(categories_matched) == 1:
      return categories_matched[0] # Return the single matched category
    else:
      # If multiple or no categories matched, use embeddings categorization
      category = embeddings_categorization(prompt)
      return category

c=0

prompts_read = []
prompt_variations_txt = []
prompt_variations_id = []

user_prompt = input("What can I help you with today? ")

#response = client.responses.create(
  #  model="gpt-4.1",
  #  input = user_prompt)

doc_id = f"user_prompt_{c}"

category = categorize_prompt(user_prompt) # Use the corrected function

print("CATEGORY: " + category)
db.collection("prompt_variations").document(doc_id).set({
    "text": user_prompt,
    "source": "user",
    "category": category, # Include category
    "created_at": datetime.datetime.utcnow().isoformat()
})

db.collection("ucb_stats").document(doc_id).set({
      "prompt_id": doc_id,
      "count": 0,
      "avg_reward": 0.0,
      "category": category, # Include category
      "created_at": datetime.datetime.utcnow().isoformat()
})

variation = "Your job is to act as a senior financial due diligence professional experienced in both investment banking and Big 4 Transaction / Restructuring / Performance Improvement Services. Give me a variation of the following prompt that will increase the performance of chatgpt in achieving high quality results, Remember, only include the revised prompt in the output, no other information or comments from you. "

variety_guidance = "Also, I want you to make sure that the prompt variation you provide me is different than the previous one, which is: "


for i in range(10):
  c+=1

  doc_ref = db.collection("previous_prompts").document("last_prompt")
  doc = doc_ref.get()

  if doc.exists:
      variety_guidance += doc.to_dict().get("text", "")


  if i <= 5:
    response = client.responses.create(
      model="gpt-4.1",
      input = user_prompt + variation + variety_guidance
    )
    print("INPUT: " + user_prompt + variation + variety_guidance)
    doc_id = f"user_prompt_{c}"
    #print(response.output_text)
    prompt_new = response.output_text
    category = categorize_prompt(prompt_new) # Categorize new prompt
    db.collection("prompt_variations").document(doc_id).set({
      "text": prompt_new,
      "source": "user",
      "category": category,
      "created_at": datetime.datetime.utcnow().isoformat()
    })

    db.collection("ucb_stats").document(doc_id).set({
        "prompt_id": doc_id,
        "count": 0,
        "avg_reward": 0.0,
        "category": category,
        "created_at": datetime.datetime.utcnow().isoformat()
    })

    print("Prompt: " + prompt_new)

    db.collection("previous_prompts").document("last_prompt").set({
      "text": prompt_new,
      "source": "user",
      "category": category,
      "created_at": datetime.datetime.utcnow().isoformat()
    })


    prompt_variations_txt.append(prompt_new)
    prompt_variations_id.append(doc_id)

  else:
    response = client.responses.create(
      model="gpt-4.1",
      input = user_prompt + variation + variety_guidance # Corrected variation2 to variation
    )
    doc_id = f"user_prompt_{c}"
    #print(response.output_text)
    prompt_new = response.output_text
    category = categorize_prompt(prompt_new) # Categorize new prompt
    db.collection("prompt_variations").document(doc_id).set({
      "text": prompt_new,
      "source": "user",
      "category": category,
      "created_at": datetime.datetime.utcnow().isoformat()
    })
    db.collection("ucb_stats").document(doc_id).set({
      "prompt_id": doc_id,
      "count": 0,
      "avg_reward": 0.0,
      "category": category,
      "created_at": datetime.datetime.utcnow().isoformat()
  })

    db.collection("previous_prompts").document("last_prompt").set({
      "text": prompt_new,
      "source": "user",
      "category": category,
      "created_at": datetime.datetime.utcnow().isoformat()
    })



    prompt_variations_txt.append(prompt_new)
    prompt_variations_id.append(doc_id)



prompt_docs = db.collection("prompt_variations").stream()

for doc in prompt_docs:
  random_idx = random.randint(0, len(general_modifiers)-1)

  print("ID of prompt to be modified: " + doc.id)

  if doc.id not in prompts_read:
    c+=1
    doc_id = f"user_prompt_{c}"
    print(doc_id)
    print(c)
    new_prompt = doc.to_dict()["text"] + general_modifiers[random_idx]
    #print(new_prompt)
    prompts_read.append(doc.id)
    category = categorize_prompt(new_prompt) # Categorize new prompt

    db.collection("prompt_variations").document(doc_id).set({
    "text": new_prompt,
    "source": "user",
    "category": category,
    "created_at": datetime.datetime.utcnow().isoformat()
    })
    db.collection("ucb_stats").document(doc_id).set({
      "prompt_id": doc_id,
      "count": 0,
      "avg_reward": 0.0,
      "category": category,
      "created_at": datetime.datetime.utcnow().isoformat()
  })

    prompt_variations_txt.append(new_prompt)
    prompt_variations_id.append(doc_id)


filtered_prompts, filtered_ids = clustering_filter(prompt_variations_txt, prompt_variations_id, n_clusters = 8)

print("Filtered prompts: " + str(filtered_prompts))

# Identify which prompt IDs to delete
unwanted_ids = set(prompt_variations_id) - set(filtered_ids)

#Delete each unwanted prompt from Firebase
for doc_id in unwanted_ids:
    # Get the document first
    doc_ref = db.collection("prompt_variations").document(doc_id)
    doc = doc_ref.get()

    if doc.exists:
        prompt_data = doc.to_dict()
        print(f"Deleting prompt: {doc_id}")
        print("Prompt text:", prompt_data.get("text"))

        # Delete the document from both collections
        doc_ref.delete()
        db.collection("ucb_stats").document(doc_id).delete()
    else:
        print(f"Document {doc_id} not found.")

'''
c=0

prompts_read = []
prompt_variations_txt = []
prompt_variations_id = []

user_prompt = input("What can I help you with today? ")

#response = client.responses.create(
  #  model="gpt-4.1",
  #  input = user_prompt)

doc_id = f"user_prompt_{c}"



db.collection("prompt_variations").document(doc_id).set({
    "text": user_prompt,
    "source": "user",
    "created_at": datetime.datetime.utcnow().isoformat()
})

db.collection("ucb_stats").document(doc_id).set({
      "prompt_id": doc_id,
      "count": 0,
      "avg_reward": 0.0,
      "created_at": datetime.datetime.utcnow().isoformat()
})

variation = "Your job is to act as a senior financial due diligence professional experienced in both investment banking and Big 4 Transaction / Restructuring / Performance Improvement Services. Give me a variation of the following prompt that will increase the performance of chatgpt in achieving high quality results, Remember, only include the revised prompt in the output, no other information or comments from you. "

variation2 = "I am currently a consultant at a Big 4 company. My job is to optimize the following Generative AI prompt to ensure it performs excellently in various tasks within the financial sector. Please take the required actions to optimize the prompt, ensuring it meets the highest professional standards. During the optimization process, keep in mind the following guidelines:  Be Specific About the Task, Don't say “analyze revenue.” Say “Write a concise revenue analysis covering QoQ growth in 2023, including one key driver of change.Use Professional Framing. Embed the prompt in your analyst mindset. ChatGPT should act as a Big 4 associate, not a blogger. 5. Guide the Tone. Use concise, neutral, analytical tone. Avoid speculative language.” Instruction Tell ChatGPT to avoid adjectives, soft qualifiers, or opinions unless asked. Anchor to KPIs Base analysis on EBITDA, gross margin, working capital swings. only include the revised prompt in the output, no other information or comments from you. "

variety_guidance = "Also, I want you to make sure that the prompt variation you provide me is different than the previous one, which is: "


for i in range(10):
  c+=1

  doc_ref = db.collection("previous_prompts").document("last_prompt")
  doc = doc_ref.get()

  if doc.exists:
      variety_guidance += doc.to_dict().get("text", "")


  if i <= 5:
    response = client.responses.create(
      model="gpt-4.1",
      input = user_prompt + variation + variety_guidance
    )
    print("INPUT: " + user_prompt + variation + variety_guidance)
    doc_id = f"user_prompt_{c}"
    #print(response.output_text)
    prompt_new = response.output_text
    db.collection("prompt_variations").document(doc_id).set({
      "text": prompt_new,
      "source": "user",
      "created_at": datetime.datetime.utcnow().isoformat()
    })

    db.collection("ucb_stats").document(doc_id).set({
        "prompt_id": doc_id,
        "count": 0,
        "avg_reward": 0.0,
        "created_at": datetime.datetime.utcnow().isoformat()
    })

    print("Prompt: " + prompt_new)

    db.collection("previous_prompts").document("last_prompt").set({
      "text": prompt_new,
      "source": "user",
      "created_at": datetime.datetime.utcnow().isoformat()
    })


    prompt_variations_txt.append(prompt_new)
    prompt_variations_id.append(doc_id)

  else:
    response = client.responses.create(
      model="gpt-4.1",
      input = user_prompt + variation2 + variety_guidance
    )
    doc_id = f"user_prompt_{c}"
    #print(response.output_text)
    prompt_new = response.output_text
    db.collection("prompt_variations").document(doc_id).set({
      "text": prompt_new,
      "source": "user",
      "created_at": datetime.datetime.utcnow().isoformat()
    })
    db.collection("ucb_stats").document(doc_id).set({
      "prompt_id": doc_id,
      "count": 0,
      "avg_reward": 0.0,
      "created_at": datetime.datetime.utcnow().isoformat()
  })

    db.collection("previous_prompts").document("last_prompt").set({
      "text": prompt_new,
      "source": "user",
      "created_at": datetime.datetime.utcnow().isoformat()
    })



    prompt_variations_txt.append(prompt_new)
    prompt_variations_id.append(doc_id)



prompt_docs = db.collection("prompt_variations").stream()

for doc in prompt_docs:
  random_idx = random.randint(0, len(general_modifiers)-1)

  print("ID of prompt to be modified: " + doc.id)

  if doc.id not in prompts_read:
    c+=1
    doc_id = f"user_prompt_{c}"
    print(doc_id)
    print(c)
    new_prompt = doc.to_dict()["text"] + general_modifiers[random_idx]
    #print(new_prompt)
    prompts_read.append(doc.id)

    db.collection("prompt_variations").document(doc_id).set({
    "text": new_prompt,
    "source": "user",
    "created_at": datetime.datetime.utcnow().isoformat()
    })
    db.collection("ucb_stats").document(doc_id).set({
      "prompt_id": doc_id,
      "count": 0,
      "avg_reward": 0.0,
      "created_at": datetime.datetime.utcnow().isoformat()
  })

    prompt_variations_txt.append(new_prompt)
    prompt_variations_id.append(doc_id)


filtered_prompts, filtered_ids = clustering_filter(prompt_variations_txt, prompt_variations_id, n_clusters = 8)

print("Filtered prompts: " + str(filtered_prompts))

# Identify which prompt IDs to delete
unwanted_ids = set(prompt_variations_id) - set(filtered_ids)

#Delete each unwanted prompt from Firebase
for doc_id in unwanted_ids:
    # Get the document first
    doc_ref = db.collection("prompt_variations").document(doc_id)
    doc = doc_ref.get()

    if doc.exists:
        prompt_data = doc.to_dict()
        print(f"Deleting prompt: {doc_id}")
        print("Prompt text:", prompt_data.get("text"))

        # Delete the document from both collections
        doc_ref.delete()
        db.collection("ucb_stats").document(doc_id).delete()
    else:
        print(f"Document {doc_id} not found.")

'''

ucb = FirebaseUCB(db)

while True:
    print("\n🚀 Selecting best prompt variant...")
    index, selected_prompt, doc_id = ucb.select_variant()

    print(f"\n📌 Selected Prompt ID: {doc_id}")
    print(f"🔍 Prompt: {selected_prompt}\n")

    # Simulate prompt being sent to OpenAI
    response = client.chat.completions.create(
        model="gpt-4",
        messages=[{"role": "user", "content": selected_prompt}]
    )
    print("🧠 Response:\n", response.choices[0].message.content)

    # User provides feedback manually
    while True:
        try:
            feedback = float(input("Rate the output quality from 0 (bad) to 1 (excellent): "))
            if 0.0 <= feedback <= 1.0:
                break
            else:
                print("❗ Please enter a number between 0 and 1.")
        except:
            print("❗ Invalid input.")

    ucb.update(index, feedback)

    cont = input("\nType 'q' to quit, anything else to continue: ")
    if cont.lower() == 'q':
        break

ucb = FirebaseUCB(db)

while True:
  user_prompt = input("What can I help you with today? ")
  category = categorize_prompt(user_prompt)

  c=0

  prompts_read = []
  prompt_variations_txt = []
  prompt_variations_id = []

  user_prompt = input("What can I help you with today? ")

  #response = client.responses.create(
    #  model="gpt-4.1",
    #  input = user_prompt)

  doc_id = f"user_prompt_{c}"

  category = categorize_prompt(user_prompt) # Use the corrected function

  print("CATEGORY: " + category)
  db.collection("prompt_variations").document(doc_id).set({
      "text": user_prompt,
      "source": "user",
      "category": category, # Include category
      "created_at": datetime.datetime.utcnow().isoformat()
  })

  db.collection("ucb_stats").document(doc_id).set({
        "prompt_id": doc_id,
        "count": 0,
        "avg_reward": 0.0,
        "category": category, # Include category
        "created_at": datetime.datetime.utcnow().isoformat()
  })

  variation = "Your job is to act as a senior financial due diligence professional experienced in both investment banking and Big 4 Transaction / Restructuring / Performance Improvement Services. Give me a variation of the following prompt that will increase the performance of chatgpt in achieving high quality results, Remember, only include the revised prompt in the output, no other information or comments from you. "

  variety_guidance = "Also, I want you to make sure that the prompt variation you provide me is different than the previous one, which is: "


  for i in range(10):
    c+=1

    doc_ref = db.collection("previous_prompts").document("last_prompt")
    doc = doc_ref.get()

    if doc.exists:
        variety_guidance += doc.to_dict().get("text", "")


    if i <= 5:
      response = client.responses.create(
        model="gpt-4.1",
        input = user_prompt + variation + variety_guidance
      )
      print("INPUT: " + user_prompt + variation + variety_guidance)
      doc_id = f"user_prompt_{c}"
      #print(response.output_text)
      prompt_new = response.output_text
      category = categorize_prompt(prompt_new) # Categorize new prompt
      db.collection("prompt_variations").document(doc_id).set({
        "text": prompt_new,
        "source": "user",
        "category": category,
        "created_at": datetime.datetime.utcnow().isoformat()
      })

      db.collection("ucb_stats").document(doc_id).set({
          "prompt_id": doc_id,
          "count": 0,
          "avg_reward": 0.0,
          "category": category,
          "created_at": datetime.datetime.utcnow().isoformat()
      })

      print("Prompt: " + prompt_new)

      db.collection("previous_prompts").document("last_prompt").set({
        "text": prompt_new,
        "source": "user",
        "category": category,
        "created_at": datetime.datetime.utcnow().isoformat()
      })


      prompt_variations_txt.append(prompt_new)
      prompt_variations_id.append(doc_id)

    else:
      response = client.responses.create(
        model="gpt-4.1",
        input = user_prompt + variation + variety_guidance # Corrected variation2 to variation
      )
      doc_id = f"user_prompt_{c}"
      #print(response.output_text)
      prompt_new = response.output_text
      category = categorize_prompt(prompt_new) # Categorize new prompt
      db.collection("prompt_variations").document(doc_id).set({
        "text": prompt_new,
        "source": "user",
        "category": category,
        "created_at": datetime.datetime.utcnow().isoformat()
      })
      db.collection("ucb_stats").document(doc_id).set({
        "prompt_id": doc_id,
        "count": 0,
        "avg_reward": 0.0,
        "category": category,
        "created_at": datetime.datetime.utcnow().isoformat()
    })

      db.collection("previous_prompts").document("last_prompt").set({
        "text": prompt_new,
        "source": "user",
        "category": category,
        "created_at": datetime.datetime.utcnow().isoformat()
      })



      prompt_variations_txt.append(prompt_new)
      prompt_variations_id.append(doc_id)



  prompt_docs = db.collection("prompt_variations").stream()

  for doc in prompt_docs:
    random_idx = random.randint(0, len(general_modifiers)-1)

    print("ID of prompt to be modified: " + doc.id)

    if doc.id not in prompts_read:
      c+=1
      doc_id = f"user_prompt_{c}"
      print(doc_id)
      print(c)
      new_prompt = doc.to_dict()["text"] + general_modifiers[random_idx]
      #print(new_prompt)
      prompts_read.append(doc.id)
      category = categorize_prompt(new_prompt) # Categorize new prompt

      db.collection("prompt_variations").document(doc_id).set({
      "text": new_prompt,
      "source": "user",
      "category": category,
      "created_at": datetime.datetime.utcnow().isoformat()
      })
      db.collection("ucb_stats").document(doc_id).set({
        "prompt_id": doc_id,
        "count": 0,
        "avg_reward": 0.0,
        "category": category,
        "created_at": datetime.datetime.utcnow().isoformat()
    })

      prompt_variations_txt.append(new_prompt)
      prompt_variations_id.append(doc_id)


  filtered_prompts, filtered_ids = clustering_filter(prompt_variations_txt, prompt_variations_id, n_clusters = 8)

  print("Filtered prompts: " + str(filtered_prompts))

  # Identify which prompt IDs to delete
  unwanted_ids = set(prompt_variations_id) - set(filtered_ids)

  #Delete each unwanted prompt from Firebase
  for doc_id in unwanted_ids:
      # Get the document first
      doc_ref = db.collection("prompt_variations").document(doc_id)
      doc = doc_ref.get()

      if doc.exists:
          prompt_data = doc.to_dict()
          print(f"Deleting prompt: {doc_id}")
          print("Prompt text:", prompt_data.get("text"))

          # Delete the document from both collections
          doc_ref.delete()
          db.collection("ucb_stats").document(doc_id).delete()
      else:
          print(f"Document {doc_id} not found.")


  # Re-initialize UCB after filtering and deleting
  ucb = FirebaseUCB(db)

  print("\n🚀 Selecting best prompt variant...")
  index, selected_prompt, doc_id = ucb.select_variant()

  # Check if a variant was successfully selected
  if selected_prompt is not None:
      print(f"\n📌 Selected Prompt ID: {doc_id}")
      print(f"🔍 Prompt: {selected_prompt}\n")

      # Simulate prompt being sent to OpenAI
      response = client.chat.completions.create(
          model="gpt-4",
          messages=[{"role": "user", "content": selected_prompt}]
      )
      print("🧠 Response:\n", response.choices[0].message.content)

      # User provides feedback manually
      while True:
          try:
              feedback = float(input("Rate the output quality from 0 (bad) to 1 (excellent): "))
              if 0.0 <= feedback <= 1.0:
                  break
              else:
                  print("❗ Please enter a number between 0 and 1.")
          except:
              print("❗ Invalid input.")

      ucb.update(index, feedback)

  else:
      print("No prompt variant was selected.")


  cont = input("\nType 'q' to quit, anything else to continue: ")
  if cont.lower() == 'q':
      break